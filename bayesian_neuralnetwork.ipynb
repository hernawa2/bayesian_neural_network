{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "84490867-e9c2-48f2-8956-6f45166853b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langevin_gradient (generic function with 1 method)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using CSV, DataFrames, Distributions, Plots, BayesNets, LinearAlgebra, StatsBase\n",
    "using Distributions, LinearAlgebra\n",
    "#Bayesian Neural Network\n",
    "\n",
    "struct self{Topo, Train, Test, learn_rate}\n",
    "    topo::Topo\n",
    "    train_data::Train\n",
    "    test_data::Test\n",
    "    lr::learn_rate\n",
    "end\n",
    "\n",
    "neural_net=self([5,10,5],[5,10,5],[5,10,5],5);\n",
    "\n",
    "struct weight{w_1,b_1,w_2,b_2}\n",
    "    weight_layer_1::w_1\n",
    "    bias_1::b_1\n",
    "    weight_layer_2::w_2\n",
    "    bias_2::b_2\n",
    "end\n",
    "\n",
    "function weight_output(neural_net)\n",
    "    #initialize weight\n",
    "    weight_layer_1=rand(Normal(0, 1), (neural_net.topo[1],neural_net.topo[2]))./sqrt(neural_net.topo[1]); #weight first layer\n",
    "    bias_1=rand(Normal(0, 1), (1,neural_net.topo[2]))./sqrt(neural_net.topo[2]); #bias first layer\n",
    "    weight_layer_2=rand(Normal(0, 1), (neural_net.topo[2],neural_net.topo[3]))./sqrt(neural_net.topo[2]); #weight second layer\n",
    "    bias_2=rand(Normal(0, 1), (1,neural_net.topo[3]))./sqrt(neural_net.topo[2]); #bias first layer\n",
    "    return [weight_layer_1, bias_1, weight_layer_2, bias_2]\n",
    "end\n",
    "\n",
    "layer=weight_output(neural_net);\n",
    "\n",
    "function compute_output(neural_net)\n",
    "    #compute hidden and last layer output\n",
    "    hidden_output=zeros(1,neural_net.topo[2]);\n",
    "    last_output=zeros(1,neural_net.topo[3]);\n",
    "    return last_output\n",
    "end\n",
    "\n",
    "function sigmoid(x)\n",
    "    return 1 ./ (1 .+ exp.(-x))\n",
    "end\n",
    "\n",
    "function sampleEr(neural_net, actualout)\n",
    "    error=compute_output(neural_net) .- actualout;\n",
    "    sqerror=sum(error.^2)/neural_net.topo[3];\n",
    "    return sqerror\n",
    "end\n",
    "\n",
    "function forward_pass(X, neural_net, layer)\n",
    "    z_1=(reshape(X,(1,neural_net.topo[1])))*layer[1] .+ layer[2];\n",
    "    hid_out=sigmoid(z_1);\n",
    "    z_2=hid_out*layer[3] .+ layer[4];\n",
    "    last_out=sigmoid(z_2);\n",
    "    return hid_out,last_out\n",
    "end\n",
    "    \n",
    "function backward_pass(inp, desired, neural_net, layer)\n",
    "    hid_out, last_out=forward_pass(X, neural_net, layer);\n",
    "    out_delta=((reshape(desired,(1,neural_net.topo[3]))) .- last_out) .* (last_out .* (1 .- last_out)); \n",
    "    hid_delta=out_delta*transpose(layer[3]) .* (hid_out .* (1 .- hid_out));\n",
    "    h_o_layer=2 # hidden to output layer\n",
    "    for i in 1:neural_net.topo[h_o_layer]\n",
    "        for j in 1:neural_net.topo[h_o_layer+1]\n",
    "            #update weight layer 2\n",
    "            layer[3][i,j] += neural_net.lr * out_delta[j] * hid_out[i]\n",
    "        end\n",
    "    end\n",
    "    for k in 1:neural_net.topo[h_o_layer+1]\n",
    "        layer[4][k] += -1 * neural_net.lr * out_delta[k]\n",
    "    end\n",
    "    \n",
    "    i_h_layer=1 #input to hidden layer\n",
    "    for i in 1:neural_net.topo[i_h_layer]\n",
    "        for j in 1:neural_net.topo[i_h_layer+1]\n",
    "            #update weight later 1\n",
    "            layer[1][i,j] += neural_net.lr * hid_delta[j] * inp[i] #placeholder for input\n",
    "        end\n",
    "    end\n",
    "    for k in 1:neural_net.topo[i_h_layer+1]\n",
    "        layer[2][k] += -1 * neural_net.lr * hid_delta[k]\n",
    "    end\n",
    "    return layer\n",
    "end\n",
    "\n",
    "function decode(w, neural_net, layer)\n",
    "    w_layer1size=neural_net.topo[1] * neural_net.topo[2];\n",
    "    w_layer2size=neural_net.topo[2] * neural_net.topo[3];\n",
    "    \n",
    "    w_layer1=w[1:w_layer1size];\n",
    "    layer[1]=reshape(layer[1],(neural_net.topo[1],neural_net.topo[2]));\n",
    "    \n",
    "    w_layer2=w[w_layer1size+1:w_layer1size + w_layer2size];\n",
    "    layer[3]=reshape(layer[3],(neural_net.topo[2],neural_net.topo[3]));\n",
    "    \n",
    "    layer[2]=w[w_layer1size+w_layer1size+1:w_layer1size+w_layer1size+neural_net.topo[2]];\n",
    "    layer[4]=w[w_layer1size+w_layer1size+neural_net.topo[2]+1:w_layer1size+w_layer1size+neural_net.topo[2]+neural_net.topo[3]];\n",
    "    return layer\n",
    "end\n",
    "\n",
    "function encode(neural_net, layer)\n",
    "    w1=reshape(collect(Iterators.flatten(layer[1])),(1,prod(size(layer[1]))));\n",
    "    w2=reshape(collect(Iterators.flatten(layer[3])),(1,prod(size(layer[3]))));\n",
    "    w=hcat(w1,w2,layer[2],layer[4]);\n",
    "    return w\n",
    "end\n",
    "\n",
    "function langevin_gradient(data, w, depth, neural_net, layer) #BP with SGD\n",
    "    layer=decode(w, neural_net, layer);\n",
    "    sz=size(data)[1];\n",
    "    \n",
    "    inp=zeros(1,neural_net.topo[1]);\n",
    "    desired=zeros(1,neural_net.topo[3]);\n",
    "    fx=zeros(sz);\n",
    "    \n",
    "    for i in 1:depth\n",
    "        for i in 1:sz\n",
    "            pat=i;\n",
    "            inp=data[pat,1:neural_net.topo[1]];\n",
    "            desired=data[pat, (neural_net.topo[1] + 1):(neural_net.topo[1]+last(neural_net.topo))];\n",
    "            hid_out, last_out=forward_pass(inp, neural_net, layer);\n",
    "            layer=backward_pass(inp, desired, neural_net, layer);\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    w_updated=encode(neural_net,layer);\n",
    "    \n",
    "    return w_updated\n",
    "end\n",
    "\n",
    "function evaluate_proposal(data, w, neural_net, layer)\n",
    "    layer=decode(w, neural_net, layer);\n",
    "    sz=size(data)[1];\n",
    "    inp=zeros(1,neural_net.topo[1]);\n",
    "    desired=zeros(1,neural_net.topo[3]);\n",
    "    \n",
    "    fx=zeros(sz,neural_net.topo[3]);\n",
    "    \n",
    "    for i in 1:sz\n",
    "        inp=data[i,1:neural_net.topo[1]];\n",
    "        hid_out, last_out=forward_pass(inp, neural_net, layer);\n",
    "        fx[i,:]=last_out;\n",
    "    end\n",
    "    return fx\n",
    "end\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "            \n",
    "            \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.4",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
